{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import image\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.util import view_as_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatePatches(X, step_size):\n",
    "    X = X.reshape((1, 512, 512, 3))\n",
    "    pe = image.PatchExtractor(patch_size=(step_size, step_size), max_patches=20)\n",
    "    pe_fit = pe.fit(X)\n",
    "    pe_trans = pe.transform(X)\n",
    "    return pe_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatePatchesAsGrid(img, step_size=64):\n",
    "    window_shape = (step_size, step_size, 3)\n",
    "    B = view_as_windows(img, window_shape, step=step_size)\n",
    "    B = B.reshape(64, 64, 64, 3)\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPatches_bag_hdf5(save_path, img_name, img_patch):\n",
    "    file_path = os.path.join(save_path, img_name) + '.h5'\n",
    "    file = h5py.File(file_path, \"w\")\n",
    "    dtype = img_patch.dtype\n",
    "    # Initialize a resizable dataset to hold the output\n",
    "    img_shape = img_patch.shape\n",
    "    maxshape = (None,) + img_shape[1:] #maximum dimensions up to which dataset maybe resized (None means unlimited)\n",
    "    dset = file.create_dataset('imgs', shape=img_shape, maxshape=maxshape, chunks=img_shape, dtype=dtype)\n",
    "#     img_patch = np.array(img_patch)[np.newaxis,...]\n",
    "    dset[:] = img_patch\n",
    "    dset.attrs['patch_level'] = 0\n",
    "    dset.attrs['wsi_name'] = img_name\n",
    "    dset.attrs['downsample'] = 0\n",
    "    dset.attrs['level_dim'] = 0\n",
    "    dset.attrs['downsampled_level_dim'] = 0\n",
    "    coord_dset = file.create_dataset('coords', shape=(20, 2), maxshape=(None, 2), chunks=(1, 2), dtype=np.int32)\n",
    "    coord_dset[:] = (0,0)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = 'tb_data/tb'\n",
    "save_path = 'tb_patches'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(source_path):\n",
    "    img_name = filename.split('.')[0]\n",
    "    source_img_path = os.path.join(source_path, img_name + '.png')\n",
    "    img = load_image(source_img_path)\n",
    "    patches = generatePatchesAsGrid(img)\n",
    "    createPatches_bag_hdf5(save_path, img_name, patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'h0001.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 64, 3)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_name = filename.split('.')[0]\n",
    "source_img_path = os.path.join(source_path, img_name + '.png')\n",
    "img = load_image(source_img_path)\n",
    "patches = generatePatchesAsGrid(img)\n",
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 64, 64, 3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_special = patches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img2 = Image.fromarray((img_special * 255).astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x1FD58002F60>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'tb_data/'\n",
    "categories = ['health', 'tb']\n",
    "cases = []\n",
    "labels = []\n",
    "for category in categories:\n",
    "    for file in os.listdir(data_folder + category):\n",
    "        case = file.split('.')[0]\n",
    "        cases.append(case)\n",
    "        labels.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'case_id': cases, 'slide_id': cases, 'label': labels}\n",
    "df = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>slide_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>h0001</td>\n",
       "      <td>h0001</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>h0003</td>\n",
       "      <td>h0003</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>h0004</td>\n",
       "      <td>h0004</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>h0005</td>\n",
       "      <td>h0005</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>h0006</td>\n",
       "      <td>h0006</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4595</td>\n",
       "      <td>tb1192</td>\n",
       "      <td>tb1192</td>\n",
       "      <td>tb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4596</td>\n",
       "      <td>tb1194</td>\n",
       "      <td>tb1194</td>\n",
       "      <td>tb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4597</td>\n",
       "      <td>tb1196</td>\n",
       "      <td>tb1196</td>\n",
       "      <td>tb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4598</td>\n",
       "      <td>tb1197</td>\n",
       "      <td>tb1197</td>\n",
       "      <td>tb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4599</td>\n",
       "      <td>tb1199</td>\n",
       "      <td>tb1199</td>\n",
       "      <td>tb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4600 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     case_id slide_id   label\n",
       "0      h0001    h0001  health\n",
       "1      h0003    h0003  health\n",
       "2      h0004    h0004  health\n",
       "3      h0005    h0005  health\n",
       "4      h0006    h0006  health\n",
       "...      ...      ...     ...\n",
       "4595  tb1192   tb1192      tb\n",
       "4596  tb1194   tb1194      tb\n",
       "4597  tb1196   tb1196      tb\n",
       "4598  tb1197   tb1197      tb\n",
       "4599  tb1199   tb1199      tb\n",
       "\n",
       "[4600 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset_csv/label_information_tb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from models.model_clam import CLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLAM(\n",
       "  (attention_net): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Attn_Net_Gated(\n",
       "      (attention_a): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (1): Tanh()\n",
       "      )\n",
       "      (attention_b): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (1): Sigmoid()\n",
       "      )\n",
       "      (attention_c): Linear(in_features=256, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (classifiers): ModuleList(\n",
       "    (0): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (1): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (instance_classifiers): ModuleList(\n",
       "    (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "    (1): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "  (instance_loss_fn): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_loss_fn = nn.CrossEntropyLoss()\n",
    "model_dict = {\"dropout\": False, 'n_classes': 2, \"size_arg\": 'small'}\n",
    "model = CLAM(**model_dict, instance_loss_fn=instance_loss_fn)\n",
    "PATH = 'results/tb_v1_s1/s_0_checkpoint.pt'\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('tb_features/h0001.h5', 'r')\n",
    "# bag_features for one image\n",
    "data = f['features']\n",
    "data_numpy = np.array(data)\n",
    "data_tensor = torch.from_numpy(data_numpy)\n",
    "logits, Y_prob, Y_hat, A, _ = model(data_tensor)\n",
    "# where A is the matrix of attention scores (n_classes x n_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.1931, -6.4510, 10.9241,  7.5645, -5.2702,  1.4068, 12.4135,  2.7285,\n",
       "         1.0446,  2.1090, -1.6018,  0.3554, -1.3929, -6.3212,  3.7848, 10.2047,\n",
       "        -1.7549,  9.9653, -0.6147,  1.9352], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
